{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read training data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data(42000,785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  pixel9  pixel10  pixel11  pixel12  pixel13  pixel14  pixel15  \\\n",
      "0       0       0        0        0        0        0        0        0   \n",
      "1       0       0        0        0        0        0        0        0   \n",
      "2       0       0        0        0        0        0        0        0   \n",
      "3       0       0        0        0        0        0        0        0   \n",
      "4       0       0        0        0        0        0        0        0   \n",
      "\n",
      "   pixel16  pixel17  pixel18      \n",
      "0        0        0        0 ...  \n",
      "1        0        0        0 ...  \n",
      "2        0        0        0 ...  \n",
      "3        0        0        0 ...  \n",
      "4        0        0        0 ...  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data({0[0]},{0[1]})\".format(train_data.shape))\n",
    "print (train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature(42000,784)\n",
      "train_label(42000)\n",
      "[1 0 1 ..., 7 6 9]\n"
     ]
    }
   ],
   "source": [
    "train_feature = train_data.iloc[:,1:].values  # split the training data to features and labels\n",
    "train_label = train_data[[0]].values.ravel()  #numpy.ravel: return a contiguous flattened array.\n",
    "print(\"train_feature({0[0]},{0[1]})\".format(train_feature.shape))\n",
    "print(\"train_label({0})\".format(len(train_label)))\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_feature(28000,784)\n"
     ]
    }
   ],
   "source": [
    "test_feature = test_data.values\n",
    "print(\"test_feature({0[0]},{0[1]})\".format(test_feature.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we can see both train_feature and test_feature are tensors with a shape of [xxx, 784], however, \n",
    "# the train_label is not a tensor. In order to perform the training, we need to convert it to a tensor, \n",
    "# which need to convert class labels from scalars to one-hot vectors like:\n",
    "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "# .......\n",
    "# We can use the code from tensorflow website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label_tensor(42000,10)\n"
     ]
    }
   ],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "train_label_tensor = dense_to_one_hot(train_label)\n",
    "train_label_tensor = train_label_tensor.astype(np.uint8)\n",
    "print(\"train_label_tensor({0[0]},{0[1]})\".format(train_label_tensor.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now both features and labels are good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before we proceed to the modeling, let us do a little visulazation work to see the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are totally 42000 training examples, each with 1 label and 784 features. Each feature actually is 28 x 28 \n",
    "# pixel picture. We can reshape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label_reshape = train_label.astype(np.uint8) # uint8 is unsigned integer (0 to 255)\n",
    "train_feature_reshape = np.array(train_feature).reshape((-1, 1, 28, 28)).astype(np.uint8) # the -1 in reshape (-1,1) means a unspecified value for rows , which here should 42000 \n",
    "test_feature_reshape = np.array(test_feature).reshape((-1, 1, 28, 28)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use the matplotlib to plot the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ab4717dd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBCe/w+9FXMBv3uzNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ab45db310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.imshow(train_feature_reshape[0][0], cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let us split the train_data into two parts, one for training (80%, 33600), one for validation (20%, 8400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One important step is that we need to normalize the image features \n",
    "# # convert from [0, 255] => [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature = np.multiply(train_feature, 1.0/255.0)\n",
    "test_feature = np.multiply(train_feature, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_feature(33600,784)\n",
      "training_label(33600,10)\n",
      "validation_feature(8400,784)\n",
      "validation_label(8400,10)\n"
     ]
    }
   ],
   "source": [
    "training_feature = train_feature[:33600]\n",
    "training_label = train_label_tensor[:33600]\n",
    "\n",
    "validation_feature = train_feature[33600:]\n",
    "validation_label = train_label_tensor[33600:]\n",
    "\n",
    "print(\"training_feature({0[0]},{0[1]})\".format(training_feature.shape))\n",
    "print(\"training_label({0[0]},{0[1]})\".format(training_label.shape))\n",
    "print(\"validation_feature({0[0]},{0[1]})\".format(validation_feature.shape))\n",
    "print(\"validation_label({0[0]},{0[1]})\".format(validation_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we can run the tensorflow as in the tensorflow tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we use the softmax model, which is:\n",
    "# y=softmax(Wx+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can now implement our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training step, implement the cross-entropy as cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# apply optimization algorithm to modify the variables and reduce the cost\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "init = tf.initialize_all_variables() # add an operation to initialize the variables we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# launch the model in a Session, and run the operation that initializes the variables\n",
    "sess = tf.Session()\n",
    "sess.run(init) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the follow training, we will use a function next_batch(self, batch_size, fake_data=False), which is defined\n",
    "# in the tutorail code, I will just copy it (some part I still don't quite understand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = training_feature.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "\n",
    "    global training_feature\n",
    "    global training_label\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "\n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        training_feature = training_feature[perm]\n",
    "        training_label = training_label[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return training_feature[start:end], training_label[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then train for 1000 times as in the tutorial\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluating Our Model\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92253\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(sess.run(accuracy, feed_dict={x: training_feature, y_: training_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917738\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "print(sess.run(accuracy, feed_dict={x: validation_feature, y_: validation_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
